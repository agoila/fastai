{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93m    Warning: no model found for 'en'\u001b[0m\n",
      "\n",
      "    Only loading the 'en' tokenizer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.learner import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mmodels\u001b[0m/  sample_submission.csv  test.csv  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "PATH='data/spooky-author/'\n",
    "\n",
    "TRN = f'{PATH}train.csv'\n",
    "TEST = f'{PATH}test.csv'\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df = pd.read_csv(TRN, low_memory=False)\n",
    "tst_df = pd.read_csv(TEST, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "EAP    7900\n",
       "HPL    5635\n",
       "MWS    6044\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df.groupby('author')['text'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df_eap = trn_df[trn_df['author']=='EAP']\n",
    "trn_df_hpl = trn_df[trn_df['author']=='HPL']\n",
    "trn_df_mws = trn_df[trn_df['author']=='MWS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df, file, author):\n",
    "    file = open(f'{PATH}{author}/{author.lower()}.txt','w')\n",
    "    trainData =\"\"\n",
    "    for idx, row in df.iterrows():\n",
    "        data = row['text']\n",
    "        if trainData == \"\":\n",
    "            trainData = data\n",
    "        else :\n",
    "            trainData += \" \" + data\n",
    "\n",
    "    file.write(trainData)\n",
    "    file.close()\n",
    "    return trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_train=  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This process , however , afforded me no means of ascertaining the dimensions of my dungeon ; as I might make its circuit , and return to the point whence I set out , without being aware of the fact ; so perfectly uniform seemed the wall .'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(spacy_tok(trn_df.text[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=spacy_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=4; bptt=70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = LanguageModelData.from_dataframes(PATH, TEXT, 'text', trn_df, tst_df, tst_df, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(TEXT, open(f'{PATH}models/TEXT.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2124, 25191, 1, 595187)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', ',', 'the', 'of', '.', 'and', 'to', 'i', 'a', 'in', 'was']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'itos': 'int-to-string'\n",
    "TEXT.vocab.itos[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'stoi': 'string to int'\n",
    "TEXT.vocab.stoi['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "     31     53      8    612\n",
       "   3075    562     18    741\n",
       "      2     33    273     12\n",
       "    153   1276      2   9643\n",
       "      2  10159     22      3\n",
       "   1385      2     62   1754\n",
       "     27      6     80      4\n",
       "     42     13      2   6780\n",
       "    304    222      7     65\n",
       "      4     23     33      3\n",
       "   7495   3454     10   7346\n",
       "      3    254      3   2329\n",
       "   2488     10    983     14\n",
       "      4    407      4      6\n",
       "     13      4  11279    130\n",
       "   4654    434      5     16\n",
       "     14     22    107     56\n",
       "     21    627  13918     33\n",
       "      8    465    181    541\n",
       "     87      2    212     46\n",
       "    190     88   7655      8\n",
       "     55      3    212   1185\n",
       "   4298     93   1118     32\n",
       "      2   2023     10    115\n",
       "      6      2     80    612\n",
       "    306   5752     47   2056\n",
       "      7      9    859      7\n",
       "      3    480    473    136\n",
       "    258      4      5      3\n",
       "   2044   3802     19    873\n",
       "      8      5     55      4\n",
       "    336    111  13229    165\n",
       "     83   1422      2   2218\n",
       "      2   1735      3     19\n",
       "    144     95    277     13\n",
       "    133     14      4    118\n",
       "    900      3    889    278\n",
       "      4    371     18   3624\n",
       "      3    403   1051      7\n",
       "    323     81     65     33\n",
       "     14     23      9   1480\n",
       "     44    124   4380      7\n",
       "   1477    655    377     27\n",
       "   5354     60      5      5\n",
       "    108     11     17     47\n",
       "      3    683     85     35\n",
       "    443   1050    645      4\n",
       "      5      5     12     12\n",
       "     16      3     37  15673\n",
       "     99    743      3      6\n",
       "    134      4    813     57\n",
       "    739     31    197   3297\n",
       "      7   1695      4   1161\n",
       "     27     56     13      4\n",
       "     12   3767  13961   1171\n",
       "      3     13      7   3344\n",
       "   6178    395      3      6\n",
       "     87    809    758   1496\n",
       "     33      5      2     24\n",
       "      9     19      6   1661\n",
       "    429    204     12   1697\n",
       "   2406    774      8     66\n",
       "      5      2     11    272\n",
       "     10    431    283      2\n",
       "     20      2    915     80\n",
       "    155      8     21      2\n",
       "    182   1934      8      6\n",
       "     11     32    945    430\n",
       "      9      2     10      2\n",
       "    727      6      3      6\n",
       "   5304     10   5999    140\n",
       "    572    132    718    435\n",
       "      2    238      3     40\n",
       "     28    630   3366   2552\n",
       "     24     26   7781     72\n",
       " [torch.cuda.LongTensor of size 75x4 (GPU 0)], Variable containing:\n",
       "   3075\n",
       "    562\n",
       "     18\n",
       "    741\n",
       "      2\n",
       "     33\n",
       "    273\n",
       "     12\n",
       "    153\n",
       "   1276\n",
       "      2\n",
       "   9643\n",
       "      2\n",
       "  10159\n",
       "     22\n",
       "      3\n",
       "   1385\n",
       "      2\n",
       "     62\n",
       "   1754\n",
       "     27\n",
       "      6\n",
       "     80\n",
       "      4\n",
       "     42\n",
       "     13\n",
       "      2\n",
       "   6780\n",
       "    304\n",
       "    222\n",
       "      7\n",
       "     65\n",
       "      4\n",
       "     23\n",
       "     33\n",
       "      3\n",
       "   7495\n",
       "   3454\n",
       "     10\n",
       "   7346\n",
       "      3\n",
       "    254\n",
       "      3\n",
       "   2329\n",
       "   2488\n",
       "     10\n",
       "    983\n",
       "     14\n",
       "      4\n",
       "    407\n",
       "      4\n",
       "      6\n",
       "     13\n",
       "      4\n",
       "  11279\n",
       "    130\n",
       "   4654\n",
       "    434\n",
       "      5\n",
       "     16\n",
       "     14\n",
       "     22\n",
       "    107\n",
       "     56\n",
       "     21\n",
       "    627\n",
       "  13918\n",
       "     33\n",
       "      8\n",
       "    465\n",
       "    181\n",
       "    541\n",
       "     87\n",
       "      2\n",
       "    212\n",
       "     46\n",
       "    190\n",
       "     88\n",
       "   7655\n",
       "      8\n",
       "     55\n",
       "      3\n",
       "    212\n",
       "   1185\n",
       "   4298\n",
       "     93\n",
       "   1118\n",
       "     32\n",
       "      2\n",
       "   2023\n",
       "     10\n",
       "    115\n",
       "      6\n",
       "      2\n",
       "     80\n",
       "    612\n",
       "    306\n",
       "   5752\n",
       "     47\n",
       "   2056\n",
       "      7\n",
       "      9\n",
       "    859\n",
       "      7\n",
       "      3\n",
       "    480\n",
       "    473\n",
       "    136\n",
       "    258\n",
       "      4\n",
       "      5\n",
       "      3\n",
       "   2044\n",
       "   3802\n",
       "     19\n",
       "    873\n",
       "      8\n",
       "      5\n",
       "     55\n",
       "      4\n",
       "    336\n",
       "    111\n",
       "  13229\n",
       "    165\n",
       "     83\n",
       "   1422\n",
       "      2\n",
       "   2218\n",
       "      2\n",
       "   1735\n",
       "      3\n",
       "     19\n",
       "    144\n",
       "     95\n",
       "    277\n",
       "     13\n",
       "    133\n",
       "     14\n",
       "      4\n",
       "    118\n",
       "    900\n",
       "      3\n",
       "    889\n",
       "    278\n",
       "      4\n",
       "    371\n",
       "     18\n",
       "   3624\n",
       "      3\n",
       "    403\n",
       "   1051\n",
       "      7\n",
       "    323\n",
       "     81\n",
       "     65\n",
       "     33\n",
       "     14\n",
       "     23\n",
       "      9\n",
       "   1480\n",
       "     44\n",
       "    124\n",
       "   4380\n",
       "      7\n",
       "   1477\n",
       "    655\n",
       "    377\n",
       "     27\n",
       "   5354\n",
       "     60\n",
       "      5\n",
       "      5\n",
       "    108\n",
       "     11\n",
       "     17\n",
       "     47\n",
       "      3\n",
       "    683\n",
       "     85\n",
       "     35\n",
       "    443\n",
       "   1050\n",
       "    645\n",
       "      4\n",
       "      5\n",
       "      5\n",
       "     12\n",
       "     12\n",
       "     16\n",
       "      3\n",
       "     37\n",
       "  15673\n",
       "     99\n",
       "    743\n",
       "      3\n",
       "      6\n",
       "    134\n",
       "      4\n",
       "    813\n",
       "     57\n",
       "    739\n",
       "     31\n",
       "    197\n",
       "   3297\n",
       "      7\n",
       "   1695\n",
       "      4\n",
       "   1161\n",
       "     27\n",
       "     56\n",
       "     13\n",
       "      4\n",
       "     12\n",
       "   3767\n",
       "  13961\n",
       "   1171\n",
       "      3\n",
       "     13\n",
       "      7\n",
       "   3344\n",
       "   6178\n",
       "    395\n",
       "      3\n",
       "      6\n",
       "     87\n",
       "    809\n",
       "    758\n",
       "   1496\n",
       "     33\n",
       "      5\n",
       "      2\n",
       "     24\n",
       "      9\n",
       "     19\n",
       "      6\n",
       "   1661\n",
       "    429\n",
       "    204\n",
       "     12\n",
       "   1697\n",
       "   2406\n",
       "    774\n",
       "      8\n",
       "     66\n",
       "      5\n",
       "      2\n",
       "     11\n",
       "    272\n",
       "     10\n",
       "    431\n",
       "    283\n",
       "      2\n",
       "     20\n",
       "      2\n",
       "    915\n",
       "     80\n",
       "    155\n",
       "      8\n",
       "     21\n",
       "      2\n",
       "    182\n",
       "   1934\n",
       "      8\n",
       "      6\n",
       "     11\n",
       "     32\n",
       "    945\n",
       "    430\n",
       "      9\n",
       "      2\n",
       "     10\n",
       "      2\n",
       "    727\n",
       "      6\n",
       "      3\n",
       "      6\n",
       "   5304\n",
       "     10\n",
       "   5999\n",
       "    140\n",
       "    572\n",
       "    132\n",
       "    718\n",
       "    435\n",
       "      2\n",
       "    238\n",
       "      3\n",
       "     40\n",
       "     28\n",
       "    630\n",
       "   3366\n",
       "   2552\n",
       "     24\n",
       "     26\n",
       "   7781\n",
       "     72\n",
       "      2\n",
       "      9\n",
       "      2\n",
       "     10\n",
       " [torch.cuda.LongTensor of size 300 (GPU 0)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(md.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'process',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'afforded',\n",
       " 'me',\n",
       " 'no',\n",
       " 'means',\n",
       " 'of',\n",
       " 'ascertaining',\n",
       " 'the']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.trn_ds[0].text[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "   31\n",
       " 3075\n",
       "    2\n",
       "  153\n",
       "    2\n",
       " 1385\n",
       "   27\n",
       "   42\n",
       "  304\n",
       "    4\n",
       " 7495\n",
       "    3\n",
       "[torch.cuda.LongTensor of size 12x1 (GPU 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.numericalize([md.trn_ds[0].text[:12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "     31     53      8    612\n",
       "   3075    562     18    741\n",
       "      2     33    273     12\n",
       "    153   1276      2   9643\n",
       "      2  10159     22      3\n",
       "   1385      2     62   1754\n",
       "     27      6     80      4\n",
       "     42     13      2   6780\n",
       "    304    222      7     65\n",
       "      4     23     33      3\n",
       "   7495   3454     10   7346\n",
       "      3    254      3   2329\n",
       "   2488     10    983     14\n",
       "      4    407      4      6\n",
       "     13      4  11279    130\n",
       "   4654    434      5     16\n",
       "     14     22    107     56\n",
       "     21    627  13918     33\n",
       "      8    465    181    541\n",
       "     87      2    212     46\n",
       "    190     88   7655      8\n",
       "     55      3    212   1185\n",
       "   4298     93   1118     32\n",
       "      2   2023     10    115\n",
       "      6      2     80    612\n",
       "    306   5752     47   2056\n",
       "      7      9    859      7\n",
       "      3    480    473    136\n",
       "    258      4      5      3\n",
       "   2044   3802     19    873\n",
       "      8      5     55      4\n",
       "    336    111  13229    165\n",
       "     83   1422      2   2218\n",
       "      2   1735      3     19\n",
       "    144     95    277     13\n",
       "    133     14      4    118\n",
       "    900      3    889    278\n",
       "      4    371     18   3624\n",
       "      3    403   1051      7\n",
       "    323     81     65     33\n",
       "     14     23      9   1480\n",
       "     44    124   4380      7\n",
       "   1477    655    377     27\n",
       "   5354     60      5      5\n",
       "    108     11     17     47\n",
       "      3    683     85     35\n",
       "    443   1050    645      4\n",
       "      5      5     12     12\n",
       "     16      3     37  15673\n",
       "     99    743      3      6\n",
       "    134      4    813     57\n",
       "    739     31    197   3297\n",
       "      7   1695      4   1161\n",
       "     27     56     13      4\n",
       "     12   3767  13961   1171\n",
       "      3     13      7   3344\n",
       "   6178    395      3      6\n",
       "     87    809    758   1496\n",
       "     33      5      2     24\n",
       "      9     19      6   1661\n",
       "    429    204     12   1697\n",
       "   2406    774      8     66\n",
       "      5      2     11    272\n",
       "     10    431    283      2\n",
       "     20      2    915     80\n",
       "    155      8     21      2\n",
       "    182   1934      8      6\n",
       "     11     32    945    430\n",
       "      9      2     10      2\n",
       " [torch.cuda.LongTensor of size 69x4 (GPU 0)], Variable containing:\n",
       "   3075\n",
       "    562\n",
       "     18\n",
       "    741\n",
       "      2\n",
       "     33\n",
       "    273\n",
       "     12\n",
       "    153\n",
       "   1276\n",
       "      2\n",
       "   9643\n",
       "      2\n",
       "  10159\n",
       "     22\n",
       "      3\n",
       "   1385\n",
       "      2\n",
       "     62\n",
       "   1754\n",
       "     27\n",
       "      6\n",
       "     80\n",
       "      4\n",
       "     42\n",
       "     13\n",
       "      2\n",
       "   6780\n",
       "    304\n",
       "    222\n",
       "      7\n",
       "     65\n",
       "      4\n",
       "     23\n",
       "     33\n",
       "      3\n",
       "   7495\n",
       "   3454\n",
       "     10\n",
       "   7346\n",
       "      3\n",
       "    254\n",
       "      3\n",
       "   2329\n",
       "   2488\n",
       "     10\n",
       "    983\n",
       "     14\n",
       "      4\n",
       "    407\n",
       "      4\n",
       "      6\n",
       "     13\n",
       "      4\n",
       "  11279\n",
       "    130\n",
       "   4654\n",
       "    434\n",
       "      5\n",
       "     16\n",
       "     14\n",
       "     22\n",
       "    107\n",
       "     56\n",
       "     21\n",
       "    627\n",
       "  13918\n",
       "     33\n",
       "      8\n",
       "    465\n",
       "    181\n",
       "    541\n",
       "     87\n",
       "      2\n",
       "    212\n",
       "     46\n",
       "    190\n",
       "     88\n",
       "   7655\n",
       "      8\n",
       "     55\n",
       "      3\n",
       "    212\n",
       "   1185\n",
       "   4298\n",
       "     93\n",
       "   1118\n",
       "     32\n",
       "      2\n",
       "   2023\n",
       "     10\n",
       "    115\n",
       "      6\n",
       "      2\n",
       "     80\n",
       "    612\n",
       "    306\n",
       "   5752\n",
       "     47\n",
       "   2056\n",
       "      7\n",
       "      9\n",
       "    859\n",
       "      7\n",
       "      3\n",
       "    480\n",
       "    473\n",
       "    136\n",
       "    258\n",
       "      4\n",
       "      5\n",
       "      3\n",
       "   2044\n",
       "   3802\n",
       "     19\n",
       "    873\n",
       "      8\n",
       "      5\n",
       "     55\n",
       "      4\n",
       "    336\n",
       "    111\n",
       "  13229\n",
       "    165\n",
       "     83\n",
       "   1422\n",
       "      2\n",
       "   2218\n",
       "      2\n",
       "   1735\n",
       "      3\n",
       "     19\n",
       "    144\n",
       "     95\n",
       "    277\n",
       "     13\n",
       "    133\n",
       "     14\n",
       "      4\n",
       "    118\n",
       "    900\n",
       "      3\n",
       "    889\n",
       "    278\n",
       "      4\n",
       "    371\n",
       "     18\n",
       "   3624\n",
       "      3\n",
       "    403\n",
       "   1051\n",
       "      7\n",
       "    323\n",
       "     81\n",
       "     65\n",
       "     33\n",
       "     14\n",
       "     23\n",
       "      9\n",
       "   1480\n",
       "     44\n",
       "    124\n",
       "   4380\n",
       "      7\n",
       "   1477\n",
       "    655\n",
       "    377\n",
       "     27\n",
       "   5354\n",
       "     60\n",
       "      5\n",
       "      5\n",
       "    108\n",
       "     11\n",
       "     17\n",
       "     47\n",
       "      3\n",
       "    683\n",
       "     85\n",
       "     35\n",
       "    443\n",
       "   1050\n",
       "    645\n",
       "      4\n",
       "      5\n",
       "      5\n",
       "     12\n",
       "     12\n",
       "     16\n",
       "      3\n",
       "     37\n",
       "  15673\n",
       "     99\n",
       "    743\n",
       "      3\n",
       "      6\n",
       "    134\n",
       "      4\n",
       "    813\n",
       "     57\n",
       "    739\n",
       "     31\n",
       "    197\n",
       "   3297\n",
       "      7\n",
       "   1695\n",
       "      4\n",
       "   1161\n",
       "     27\n",
       "     56\n",
       "     13\n",
       "      4\n",
       "     12\n",
       "   3767\n",
       "  13961\n",
       "   1171\n",
       "      3\n",
       "     13\n",
       "      7\n",
       "   3344\n",
       "   6178\n",
       "    395\n",
       "      3\n",
       "      6\n",
       "     87\n",
       "    809\n",
       "    758\n",
       "   1496\n",
       "     33\n",
       "      5\n",
       "      2\n",
       "     24\n",
       "      9\n",
       "     19\n",
       "      6\n",
       "   1661\n",
       "    429\n",
       "    204\n",
       "     12\n",
       "   1697\n",
       "   2406\n",
       "    774\n",
       "      8\n",
       "     66\n",
       "      5\n",
       "      2\n",
       "     11\n",
       "    272\n",
       "     10\n",
       "    431\n",
       "    283\n",
       "      2\n",
       "     20\n",
       "      2\n",
       "    915\n",
       "     80\n",
       "    155\n",
       "      8\n",
       "     21\n",
       "      2\n",
       "    182\n",
       "   1934\n",
       "      8\n",
       "      6\n",
       "     11\n",
       "     32\n",
       "    945\n",
       "    430\n",
       "      9\n",
       "      2\n",
       "     10\n",
       "      2\n",
       "    727\n",
       "      6\n",
       "      3\n",
       "      6\n",
       " [torch.cuda.LongTensor of size 276 (GPU 0)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(md.trn_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz = 200  # size of each embedding vector\n",
    "nh = 500     # number of hidden activations per layer\n",
    "nl = 3       # number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = md.get_model(opt_fn, em_sz, nh, nl,\n",
    "               dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a638d4260814cfeb0ffc8043aeabca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1809/2124 [08:33<01:29,  3.52it/s, loss=25.3]"
     ]
    }
   ],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEOCAYAAACaQSCZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d49d6c4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c896783b3e545ae8c63e0a0d22655da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2124 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/2124 [00:00<?, ?it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 1/2124 [00:00<10:58,  3.22it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 1/2124 [00:00<22:36,  1.57it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 2/2124 [00:00<11:21,  3.12it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 2/2124 [00:00<16:12,  2.18it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 3/2124 [00:00<10:49,  3.27it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 3/2124 [00:01<14:48,  2.39it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 4/2124 [00:01<11:07,  3.18it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 4/2124 [00:01<14:05,  2.51it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 5/2124 [00:01<11:17,  3.13it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 5/2124 [00:01<12:59,  2.72it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 6/2124 [00:01<10:49,  3.26it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 6/2124 [00:02<12:36,  2.80it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 7/2124 [00:02<10:49,  3.26it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 7/2124 [00:02<12:03,  2.92it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 8/2124 [00:02<10:33,  3.34it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 8/2124 [00:02<12:01,  2.93it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 9/2124 [00:02<10:41,  3.30it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 9/2124 [00:03<11:59,  2.94it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 10/2124 [00:03<10:48,  3.26it/s, loss=10.1]\u001b[A\n",
      "  0%|          | 10/2124 [00:03<11:41,  3.01it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 11/2124 [00:03<10:37,  3.31it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 11/2124 [00:03<11:45,  3.00it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 12/2124 [00:03<10:46,  3.27it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 12/2124 [00:03<11:30,  3.06it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 13/2124 [00:03<10:37,  3.31it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 13/2124 [00:04<11:30,  3.06it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 14/2124 [00:04<10:41,  3.29it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 14/2124 [00:04<11:28,  3.07it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 15/2124 [00:04<10:42,  3.28it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 15/2124 [00:04<11:22,  3.09it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 16/2124 [00:04<10:39,  3.30it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 16/2124 [00:05<11:21,  3.10it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 17/2124 [00:05<10:40,  3.29it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 17/2124 [00:05<11:12,  3.13it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 18/2124 [00:05<10:34,  3.32it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 18/2124 [00:05<11:14,  3.12it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 19/2124 [00:05<10:38,  3.29it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 19/2124 [00:06<11:12,  3.13it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 20/2124 [00:06<10:39,  3.29it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 20/2124 [00:06<11:01,  3.18it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 21/2124 [00:06<10:29,  3.34it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 21/2124 [00:06<11:04,  3.16it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 22/2124 [00:06<10:34,  3.31it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 22/2124 [00:06<10:58,  3.19it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 23/2124 [00:06<10:30,  3.33it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 23/2124 [00:07<10:49,  3.23it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 24/2124 [00:07<10:22,  3.37it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 24/2124 [00:07<10:45,  3.25it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 25/2124 [00:07<10:19,  3.39it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 25/2124 [00:07<10:42,  3.27it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 26/2124 [00:07<10:17,  3.40it/s, loss=10.1]\u001b[A\n",
      "  1%|          | 26/2124 [00:07<10:45,  3.25it/s, loss=10.1]\u001b[A\n",
      "  1%|▏         | 27/2124 [00:08<10:21,  3.37it/s, loss=10.1]\u001b[A\n",
      "  1%|▏         | 27/2124 [00:08<10:42,  3.27it/s, loss=10.1]\u001b[A\n",
      "  1%|▏         | 28/2124 [00:08<10:18,  3.39it/s, loss=10.1]\u001b[A\n",
      "  1%|▏         | 28/2124 [00:08<10:37,  3.29it/s, loss=10.1]\u001b[A\n",
      "  1%|▏         | 29/2124 [00:08<10:15,  3.40it/s, loss=10.1]\u001b[A\n",
      "\n",
      "  1%|▏         | 29/2124 [00:08<10:31,  3.32it/s, loss=10.1]\u001b[A\n",
      "                                                              A\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       6.62048  6.58543]                                  \n",
      "[ 1.       6.35803  6.35355]                                  \n",
      "[ 2.       6.30832  6.3143 ]                                  \n",
      "[ 3.       6.15483  6.14278]                                  \n",
      "[ 4.       6.03459  6.04273]                                  \n",
      "[ 5.       5.97573  6.00109]                                  \n",
      "[ 6.       5.97683  5.99183]                                  \n",
      "[ 7.       5.93329  5.92607]                                  \n",
      "[ 8.       5.86396  5.86616]                                  \n",
      "[ 9.       5.81053  5.82366]                                  \n",
      "[ 10.        5.79955   5.79208]                               \n",
      "[ 11.        5.74794   5.77151]                               \n",
      "[ 12.        5.73369   5.76351]                               \n",
      "[ 13.        5.74033   5.75638]                               \n",
      "[ 14.        5.72786   5.75471]                               \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.fit(1e-4, 4, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('adam1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.fit(3e-3, 4, wds=1e-6, cycle_len=10, cycle_save_name='adam3_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('adam3_10_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.fit(3e-3, 1, wds=1e-6, cycle_len=20, cycle_save_name='adam3_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_cycle('adam3_20', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('adam3_20_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(4.165)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can play around with our language model a bit to check it seems to be working OK. First, let's create a short bit of text to 'prime' a set of predictions. We'll use our torchtext field to numericalize it so we can feed it to our language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m=learner.model\n",
    "ss=\"\"\". So, it wasn't quite was I was expecting, but I really liked it anyway! The best\"\"\"\n",
    "s = [spacy_tok(ss)]\n",
    "t=TEXT.numericalize(s)\n",
    "' '.join(s[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We haven't yet added methods to make it easy to test a language model, so we'll need to manually go through the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set batch size to 1\n",
    "m[0].bs=1\n",
    "# Turn off dropout\n",
    "m.eval()\n",
    "# Reset hidden state\n",
    "m.reset()\n",
    "# Get predictions from model\n",
    "res,*_ = m(t)\n",
    "# Put the batch size back to what it was\n",
    "m[0].bs=bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's see what the top 10 predictions were for the next word after our short text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nexts = torch.topk(res[-1], 10)[1]\n",
    "[TEXT.vocab.itos[o] for o in to_np(nexts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "...and let's see if our model can generate a bit more text all by itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(ss,\"\\n\")\n",
    "for i in range(50):\n",
    "    n=res[-1].topk(2)[1]\n",
    "    n = n[1] if n.data[0]==0 else n[0]\n",
    "    print(TEXT.vocab.itos[n.data[0]], end=' ')\n",
    "    res,*_ = m(n[0].unsqueeze(0))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = pickle.load(open(f'{PATH}models/TEXT.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB_LABEL = data.Field(sequential=False)\n",
    "splits = torchtext.datasets.IMDB.splits(TEXT, IMDB_LABEL, 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = splits[0].examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.label, ' '.join(t.text[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md2 = TextData.from_splits(PATH, splits, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = md2.get_model(opt_fn, 1500, bptt, emb_sz=em_sz, n_hid=nh, n_layers=nl, \n",
    "           dropout=0.1, dropouti=0.4, wdrop=0.5, dropoute=0.05, dropouth=0.3)\n",
    "m3.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "m3.load_encoder(f'adam3_20_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.clip=25.\n",
    "lrs=np.array([1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.freeze_to(-1)\n",
    "m3.fit(lrs/2, 1, metrics=[accuracy])\n",
    "m3.unfreeze()\n",
    "m3.fit(lrs, 1, metrics=[accuracy], cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m3.fit(lrs, 7, metrics=[accuracy], cycle_len=2, cycle_save_name='imdb2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.load_cycle('imdb2', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(*m3.predict_with_targs())"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/6f8810c70b400a619fdfd318904e9a5d"
  },
  "gist": {
   "data": {
    "description": "courses/dl1/my_nbs/spooky-author.ipynb",
    "public": true
   },
   "id": "6f8810c70b400a619fdfd318904e9a5d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "123px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
